## redis三节点主从集群部署

### 1.环境准备

| 主机 | ip              | 端口                     |
| ---- | --------------- | ------------------------ |
| vm1  | 192.168.168.128 | 7001、7002、17001、17002 |
| vm2  | 192.168.168.129 | 7003、7004、17003、17004 |
| vm3  | 192.168.168.130 | 7005、7006、17005、17006 |

### 2.部署

##### 2.1下载包

```sh
1.ansible vms -m shell -a "wget http://download.redis.io/releases/redis-4.0.14.tar.gz"
2.ansible vms -m shell -a "tar -xvf redis-4.0.14.tar.gz"
3.ansible vms -m shell -a " yum -y install tcl  gcc-c++  ruby rubygems"
4.ansible vms -m shell -a "curl -sSL https://rvm.io/mpapis.asc | gpg2 --import -"
5.ansible vms -m shell -a "curl -sSL https://rvm.io/pkuczynski.asc | gpg2 --import -"
6.ansible vms -m shell -a "curl -L get.rvm.io | bash -s stable" #安装rvm
7.source /usr/local/rvm/scripts/rvm
8.rvm list known #查看rvm库中的ruby版本
9.rvm install  2.4.0  #安装一个ruby版本（注意大于2.3.0版本）
10.rvm usr 2.4.0 #使用一个ruby版本
11.rvm remove 2.2.0 #卸载一个已知版本
12.rvm 	--version #查看版本
13.gem install redis #安装redis
```

##### 2.2安装redis

```sh
1.192.168.168.128节点	
	1.cd  redis-4.0.14
	2. make PREFIX=/usr/local/redis install   #安装在/usr/local/redis目录下
	3.cd src/
	4.make test #测试
	5.ll /usr/local/redis/bin/redis-*
	6.mkdir /usr/local/redis/conf
	7.cp /root/redis-4.0.14/redis.conf /usr/local/redis/conf
	8.mv /usr/local/redis/conf/redis.conf  /usr/local/redis/conf/redis-7001.conf
	9.cp /usr/local/redis/conf/redis.conf  /usr/local/redis/conf/redis-7002.conf
	10.vim  /usr/local/redis/conf/redis-7001.conf 
		bind 0.0.0.0
		protected-mode yes
		port 7001	#每个节点不同
		tcp-backlog 511
		timeout 0
		tcp-keepalive 300
		daemonize yes
		supervised no
		pidfile /usr/local/redis/conf/redis_7001.pid	#每个节点不同
		loglevel notice
		logfile ""
		databases 16
		always-show-logo yes
		save 900 1
		save 300 10
		save 60 10000
		stop-writes-on-bgsave-error yes
		rdbcompression yes
		rdbchecksum yes
		dbfilename dump-7001.rdb	#每个节点不同
		dir ./
		masterauth 1234561qaz
		slave-serve-stale-data yes
		slave-read-only yes
		repl-diskless-sync no
		repl-diskless-sync-delay 5
		repl-disable-tcp-nodelay no
		slave-priority 100
		requirepass 1234561qaz  #此处设置密码，需要修改client.rb文件中对应的password
		lazyfree-lazy-eviction no
		lazyfree-lazy-expire no
		lazyfree-lazy-server-del no
		slave-lazy-flush no
		appendonly yes
		appendfilename "appendonly-7001.aof"	#每个节点不同
		appendfsync everysec
		no-appendfsync-on-rewrite no
		auto-aof-rewrite-percentage 100
		auto-aof-rewrite-min-size 64mb
		aof-load-truncated yes
		aof-use-rdb-preamble no
		lua-time-limit 5000
		cluster-enabled yes
		cluster-config-file nodes-7001.conf	#每个节点不同
		cluster-node-timeout 15000
		slowlog-log-slower-than 10000
		slowlog-max-len 128
		latency-monitor-threshold 0
		notify-keyspace-events ""
		hash-max-ziplist-entries 512
		hash-max-ziplist-value 64
		list-max-ziplist-size -2
		list-compress-depth 0
		set-max-intset-entries 512
		zset-max-ziplist-entries 128
		zset-max-ziplist-value 64
		hll-sparse-max-bytes 3000
		activerehashing yes
		client-output-buffer-limit normal 0 0 0
		client-output-buffer-limit slave 256mb 64mb 60
		client-output-buffer-limit pubsub 32mb 8mb 60
		hz 10
		aof-rewrite-incremental-fsync yes
[root@vm1]# sed -i 's/:password => "nil",/:password => "1234561qaz",/'  /usr/local/rvm/gems/ruby-2.4.0/gems/redis-4.1.3/lib/redis/client.rb

2.192.168.168.129节点和192.168.168.130节点参照192.168.168.128节点配置
	192.168.168.129节点对应redis-7003.conf  redis-7004.conf
	192.168.168.130节点对应redis-7005.conf  redis-7006.conf
3.ansible vms -m shell -a 'ln -snvf /usr/local/redis/bin/redis-* /usr/local/bin/'
4.redis-server /usr/local/redis/conf/redis-7001.conf
  redis-server /usr/local/redis/conf/redis-7002.conf
  redis-server /usr/local/redis/conf/redis-7003.conf
  redis-server /usr/local/redis/conf/redis-7004.conf
  redis-server /usr/local/redis/conf/redis-7005.conf
  redis-server /usr/local/redis/conf/redis-7006.conf
5./root/redis-4.0.14/src/redis-trib.rb create --replicas 1 \
  192.168.168.128:7001 \
  192.168.168.129:7003 \
  192.168.168.130:7005 \
  \
  192.168.168.128:7002 \
  192.168.168.129:7004 \
  192.168.168.130:7006
6.连接
	1.redis-cli -c -h 192.168.168.128 -p 7001  -a 1234561qaz
	2.redis-cli -c -h 192.168.168.128 -p 7001
	192.168.168.128:7001> ping
	(error) NOAUTH Authentication required.
	192.168.168.128:7001> auth '1234561qaz'
	OK
```

### 3.redis外部常用命令

##### 3.1查看集群状态

```sh
./redis-trib.rb	 check 	192.168.168.128:7001

./redis-trib.rb	 info  192.168.168.128:7001
```

##### 3.2修复集群

```sh
./redis-trib.rb  fix  192.168.168.128:7001
#修复未分配的slot，状态处于importing或者migrating的solt
```

##### 3.3删除节点

```sh
./redis-trib.rb del-node host:port node_id
#删除节点之前，其对应的槽必须为空，所以在删除之前将所有的slot迁移到其他节点，其对应的slave也会指向目标节点
./redis-trib.rb  reshard  	192.168.168.128:7001	#分配槽
```

##### 3.4新增节点

```sh
./redis-trib.rb add-node new_host:new_port existing_host:existing_port --slave --master-id <arg>
#新节点必须为空，也不能在其他集群中，否则会报错

./redis-trib.rb add-node new_host:new_port existing_host:existing_port
#添加主节点
```

##### 3.5将外部redis数据导入集群

```sh
./redis-trib.rb  import  --from  x.x.x.x:xxxx  --replace  192.168.168.128:7001
```

##### 3.6迁移slot

```sh
./redis-trib.rb  reshard  192.168.168.128:7001
#交互命令中使用

redis-trib.rb reshard host:port --from <arg> --to <arg> --slots <arg> --yes --timeout <arg> --pipeline <arg>
#命令行中使用
#host:port：必传参数，集群内任意节点地址，用来获取整个集群信息。
#--from：源节点id，如果有多个源节点，使用逗号分隔，如果是all，则源节点为集群内出目标节点外的其它所有主节点。
#--to：目标节点id，只能填写一个。
#--slots：需要迁移槽的总数量。
#--yes：迁移无需用户手动确认。
#--timeout：控制每次migrate操作的超时时间，默认为60000毫秒。
#--pipeline：控制每次批量迁移键的数量，默认为10。
redis-trib.rb reshard 192.168.168.128:7001 \
--from a8b3d0f9b12d63dab3b7337d602245d96dd55844 \
--to f413fb7e6460308b17cdb71442798e1341b56cbc  \
--slots 500 \
--yes \
--pipeline 20
```

##### 3.7在集群所有节点上执行命令

```sh
./redis-trib.rb call host:port command arg arg .. arg

./redis-trib.rb  call 192.168.168.128:7001  set  name kobe 
```

### 4.redis内部常用命令

##### 4.1查看key的数量

```sh
select 1 #单机模式是有16个数据库，但是集群模式下默认只有一个SELECT 0 
dbsize  #统计数据库的key的数量
keys *  #生产环境慎用
cluster nodes  #查看节点主从情况
exist $key	#查看key是否存在
```

##### 4.2增删改查

```sh
1.字符串string
	set $key $value
	rename $key1 $key2 
	del $key
	flushdb #清空所有key
	get $key
	exists $key  #查询是否存在
2.集合set
	sadd set_ay_key "ay" "a1" "xy" "x1"  #生成set集合，添加四个数据
	smembers  set_ay_key  #查询set里面所有值
	srem  set_ay_key   "x1" #删除value为"x1"，返回为1，没有返回为0
3.集合list
	lpush list_ay_key "ay" "al" "xy" "xl"  #添加key为list_ay_key的list集合
	lrange list_ay_key 0 -1	#查询key为list_ay_key的集合
	                   0  1	#查看前两个
	                   0  2	#查看前三个
	                   0  3	#查看前四个
	rpush list_ay_key "together"	#往list尾部添加元素
	lpush list_ay_key "first"	#往list头部添加元素
	lset list_ay_key 0 "update_first"	#更新index为0的值
	lrem list_ay_key 0 "update_first"	#删除index为1上的值
4.集合hash（类似于java的增删改查）
  也叫map类型
	flushdb
	hgetall hash_ay_key #获得集合所有的key和value
	hset hash_ay_key "uuid_one" "12345"	#生成hash集合，并添加key 为uuid_one value 为"12345"
	hlen hash_ay_key 	
	hkeys hash_ay_key	#返回集合所有的key
	hvals hash_ay_key	#返回集合所有的value
	hset  hash_ay_key "uuid_two" "22222"	#集合添加值
	hget hash_ay_key uuid_two #查询key为uuid_two的值
	hset hash_ay_key "uuid_one" "11111" #更新值
5.集合sortedset
	zrange 	zset_ay_key 0 -1
	zadd	zset_ay_key 1 "ay"
	zadd	zset_ay_key 2 "a1"
	zadd 	zset_ay_key 3 "xy"
	zadd 	zset_ay_key 4 "x1"
	zrem 	zset_ay_key "x1"
6.有时候为了方便查询，通常可以使用层级或者目录
	set country:kobe  America
	get country:kobe  
7.redis集群查看删除节点信息
#三节点上一般有六个端口需要查询和删除操作
redis-cli -a 123456 -c -h 192.168.220.6 -p 7001 keys "$keyname:*"
redis-cli -a 123456 -c -h 192.168.220.6 -p 7001 keys "$keyname:*" | xargs -r -t -n1 redis-cli -a 123456 -c -h 192.168.220.6 -p 7001 del
```

### 5.redis数据库的持久化

```sh
因为redis是内存型数据库，一旦服务器进程退出或者宕机就会导致数据丢失，因此，redis提供了两种持久化数据的方案
```

##### 5.1RDB持久化

```sh
1.将redis在内存中的的状态保存到硬盘中，它可以手动执行，也可以再redis.conf中配置，定期执行
2.产生的RDB文件是一个经过压缩的二进制文件，这个文件被保存在硬盘中，redis可以通过这个文件还原数据库当时的状态
3.两种方式完成持续化操作
	3.1通过手动进行持久化操作
	save	#阻塞redis的服务器进程，直到RDB文件被创建完毕，其他指令不能执行
	bgsave	#非阻塞式存盘，Redis 会在后台异步执行快照操作，此时 Redis 仍然可以相应客户端请求。具体操作是 Redis 			进程执行 fork 操作创建子进程，RDB 持久化过程由子进程负责，完成后自动结束。Redis 只会在 fork 期间				发生阻塞，但是一般时间都很短。但是如果 Redis 数据量特别大，fork 时间就会变长，而且占用内存会加倍，			   这一点需要特别注意
	3.2通过配置文件自动
	#   save ""		是用来禁止持久化的，如果不需要刻意去掉#
	save 900 1
	save 300 10
	save 60 10000
	dbfilename dump.rdb
4.还原
	RDB文件的载入一般情况是自动的，redis服务器启动的时候，redis服务器再启动的时候如果检测到RDB文件的存在，那么redis会自动载入这个文件
5.优缺点
	优点:	高性能的持久化，创建一个子进程来进行持久化，先将数据写入一个临时文件，持久化结束后，再用这个文件代			 替上次持久化好的文件，过程中主进程不做任何IO操作
		 是个大数据回复，且对数据完整性要求不是很高的场合
	缺点：最后一次之持久化的数据可能会丢失
```

##### 5.2AOF持久化

```sh
1.通过保存Redis服务器锁执行的写状态来记录数据库的
2.记录redis服务所有操作，每秒一次，cat可以查看，不断将新写操作追加到文件末尾
3.配置文件
	appendonly yes
	appendfilename "appendonly.aof"
	no-appendfsync-on-rewrite no #no表示重写时候进行fsync操作，yes表示不进行fsync操作，官方建议no，最为安全
	auto-aof-rewrite-percentage 100	#当前AOF文件是上次重写得到AOF文件两倍时，自动重启新的日志重写过程
	auto-aof-rewrite-min-size 64mb	#当前AOF文件启动重写的最小值，避免刚启动redis，文件较小而频繁重写
4.同时开启RDB和AOF，服务器会优先选择AOF中的数据来回复数据库状态
5.appendfsync  默认是配置为everysec
	always	将缓存区的内容总是即时写到AOF文件中
	everysec	将缓存区的内容每隔一秒写入AOF文件中
	no	写入AOF文件中的操作由操作系统决定，为了提高效率，操作系统会等待缓存区被填满，才会开始同步数据到磁盘
6.还原
	redis在载入AOF文件的时候，会创建一个虚拟的client，把AOF中每一条命令都执行一遍，最终还原回数据库的状态，它的	  载入也是自动的
7.AOF重写
	7.1 AOF文件会随着时间越来越大，可以利用AOF的重写功能，控制AOF文件大小
	7.2 AOF重写功能会先读取redis现有的键值对状态，然后根据类型使用命令替代之前的多条命令
	7.3 AOF重写有大量写入操作，所以redis用子进程处理AOF重写，这意味着此时主进程数据被修改，备份数据和主库数据将		 会有不一致情况发生
	7.4 因此，redis设置了一个AOF重写缓冲区，这个缓冲区在子进程被创建之后开始使用
	7.5 这期间所有命令会被存两份，一份在AOF重写缓冲区，一份在AOF缓存空间
	7.6 当AOF重写完成后，子进程发送信号给主进程，通知主进程将AOF重写缓冲区的内容添加到AOF文件中
	7.7	no-appendfsync-on-rewrite no 
8.优缺点
	优点：	AOF更安全，可将数据及时同步到文件中
	缺点： AOF需要更多的磁盘IO，AOF文件较大，回复较慢
```

















